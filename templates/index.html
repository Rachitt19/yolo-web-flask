<!DOCTYPE html>
<html>
<head>
    <title>YOLOv8 Detection</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
</head>
<body>
    <h1> Real-Time Detection</h1>

    <div class="controls">
        <button onclick="setMode('webcam')">🎥 Webcam Mode</button>
        <button onclick="setMode('upload')">🖼️ Image Upload</button>
        <input type="file" id="imageInput" accept="image/*" onchange="uploadImage()" style="display:none;">
        <button onclick="takeScreenshot()">📸 Screenshot</button>
    </div>

    <div id="videoContainer">
        <img id="webcamFeed" src="{{ url_for('video') }}" alt="Webcam Feed" style="display:block;">
        <img id="uploadedResult" style="display:none; max-width: 100%;">
    </div>

    <div id="detectionTag">🔍 Detecting...</div>

<script>
const synth = window.speechSynthesis;
let lastSpokenClasses = new Set();
let detectionPaused = false;

let alertPlaying = false;
let personCurrentlyDetected = false;

// Function to speak detected classes
function speakClasses(classes) {
    // Only speak new classes not spoken before
    const newClasses = classes.filter(c => !lastSpokenClasses.has(c));
    if (newClasses.length === 0) return;
    
    const utterance = new SpeechSynthesisUtterance("Detected " + newClasses.join(", "));
    synth.speak(utterance);

    newClasses.forEach(c => lastSpokenClasses.add(c));
}

// Poll backend every 2 seconds for detected classes
async function pollDetections() {
    if (detectionPaused) return;
    try {
        const response = await fetch('/detected_classes');
        const classes = await response.json();
        if (classes.length > 0) {
            speakClasses(classes);
            triggerAlert(classes);
        } else {
            // No person detected → reset alert state so next person triggers sound again
            if (personCurrentlyDetected) {
                personCurrentlyDetected = false;
                alertPlaying = false;
            }
        }
    } catch (e) {
        console.error("Error fetching detected classes:", e);
    }
}

// Trigger visual and audio alert when person detected (once per detection)
function triggerAlert(classes) {
    if (classes.includes("person")) {
        if (!personCurrentlyDetected) {
            showAlert("Person detected!");
            playAlertSound();
            personCurrentlyDetected = true;
        }
    } else {
        personCurrentlyDetected = false;
        alertPlaying = false;
    }
}

function showAlert(message) {
    let alertBox = document.getElementById("alertBox");
    if (!alertBox) {
        alertBox = document.createElement("div");
        alertBox.id = "alertBox";
        alertBox.style.position = "fixed";
        alertBox.style.top = "20px";
        alertBox.style.left = "50%";
        alertBox.style.transform = "translateX(-50%)";
        alertBox.style.background = "red";
        alertBox.style.color = "white";
        alertBox.style.padding = "15px 30px";
        alertBox.style.fontSize = "20px";
        alertBox.style.borderRadius = "8px";
        alertBox.style.zIndex = 1000;
        alertBox.style.boxShadow = "0 0 15px 5px red";
        document.body.appendChild(alertBox);
    }
    alertBox.textContent = message;
    alertBox.style.display = "block";
    setTimeout(() => {
        alertBox.style.display = "none";
    }, 4000);
}

// Play alert sound (only if not already playing)
function playAlertSound() {
    if (alertPlaying) return;
    alertPlaying = true;
    const audio = new Audio("https://actions.google.com/sounds/v1/alarms/alarm_clock.ogg");
    audio.play();
    audio.onended = () => {
        alertPlaying = false;
    };
}

// Voice command recognition setup
const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
recognition.continuous = true;
recognition.lang = 'en-US';

recognition.onresult = (event) => {
    const transcript = event.results[event.results.length -1][0].transcript.trim().toLowerCase();
    console.log("Voice command received:", transcript);
    if (transcript.includes("pause detection")) {
        detectionPaused = true;
        showAlert("Detection Paused");
    } else if (transcript.includes("resume detection")) {
        detectionPaused = false;
        showAlert("Detection Resumed");
        pollDetections(); // restart polling immediately
    } else if (transcript.includes("switch to image mode")) {
        setMode('upload');
        showAlert("Switched to Image Mode");
    } else if (transcript.includes("switch to webcam mode")) {
        setMode('webcam');
        showAlert("Switched to Webcam Mode");
    }
};

recognition.onerror = (event) => {
    console.error("Speech recognition error", event.error);
};

recognition.onend = () => {
    console.log("Speech recognition ended, restarting...");
    recognition.start();
};

// Start recognition on page load
recognition.start();

// Start polling detections every 2 seconds
setInterval(pollDetections, 2000);
</script>
</body>
</html>